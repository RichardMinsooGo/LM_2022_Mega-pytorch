<img src="./mega.png" width="450px"></img>

## Mega - Pytorch (wip)

Implementation of <a href="https://arxiv.org/abs/2209.10655">Mega</a>, the Single-head Attention with Multi-headed EMA architecture that currently holds SOTA on Long Range Arena

## Citations

```bibtex
@inproceedings{Ma2022MegaMA,
    title   = {Mega: Moving Average Equipped Gated Attention},
    author  = {Xuezhe Ma and Chunting Zhou and Xiang Kong and Junxian He and Liangke Gui and Graham Neubig and Jonathan May and Luke Zettlemoyer},
    year    = {2022}
}
```
